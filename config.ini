[DEFAULT]
repeat = 10
results_directory = ./results

# SUMO Parameters
sumo_binary = /usr/bin/sumo
sumo_cfg = ./scenarios/SUMO/street.sumocfg
sumo_step_length = 0.1
start = 0
duration = 13
step_length = 0.1

# Task Scheduling Parameters
task_generation = (10, 20, 30, 40)
task_priority = -1

task_complexity = randint(1,4)
car_processing_power = randint(2,4)
task_deadline = randint(2,5)
policy = (RandomPolicy, EarliestDeadline, LowestComplexity)

; lambda_exp = 1 # rate_lambda = 1 / mean
lambda_exp = (0.5, 1, 2)

# Reinforcement Learning
max_cars = 5
; max_complexity = 2
; max_deadline = 4
; max_processing_power = 2
n_episodes = 1000
replay_buffer_capacity = 1000
batch_size = 32
learning_rate  = 0.005
gamma = 0.99

# Epsilon (exponential)
epsilon_decay_rate = 0.008
# Epsilon (linear)
epsilon_max = 1.0
epsilon_min = 0.1
epsilon_decay  = ${n_episodes}

target_update_freq = 10
rl_environment =
rl_agent =
explore = True

[RL-training]
repeat = 1

lambda_exp = 2

task_complexity = 2
car_processing_power = uniform(1,3)
task_deadline = 1

rl_environment = TaskSchedulingEnv
rl_agent = DQNAgent
policy = DQNPolicy
explore = True

duration = 100